{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqXm4uZ5yVYO",
        "outputId": "325d245a-dcdc-4c27-9434-b8fdecbb4756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWn2_Hy99K92",
        "outputId": "ee785977-f234-4aa0-c78d-53a6e434860f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  text_type                                               text\n",
            "0       ham  make sure alex knows his birthday is over in f...\n",
            "1       ham  a resume for john lavorato thanks vince i will...\n",
            "2      spam  plzz visit my website moviesgodml to get all m...\n",
            "3      spam  urgent your mobile number has been awarded wit...\n",
            "4       ham  overview of hr associates analyst project per ...\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16278 entries, 0 to 16277\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   text_type  16278 non-null  object\n",
            " 1   text       16278 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 254.5+ KB\n",
            "None\n",
            "text_type\n",
            "ham     11469\n",
            "spam     4809\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_data = pd.read_csv('train_spam.csv')\n",
        "\n",
        "print(train_data.head())\n",
        "print(train_data.info())\n",
        "print(train_data['text_type'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-gs-Vp00-Zop"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "train_data['text'] = train_data['text'].apply(preprocess_text)\n",
        "vectorizer = TfidfVectorizer(max_features=1000, min_df=5, max_df=0.7)\n",
        "\n",
        "X = vectorizer.fit_transform(train_data['text']).toarray()\n",
        "\n",
        "y = train_data['text_type'].values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Uhi6n6t_584",
        "outputId": "7df9ea69-d467-4d34-a65a-3ccddc34ecc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "label_encoder.fit(y)\n",
        "encoded_y = label_encoder.transform(y)\n",
        "\n",
        "encoded_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0zG_4MktwRp",
        "outputId": "0a664425-3e09-4872-f275-1d3a0e485b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2954294139329156\n"
          ]
        }
      ],
      "source": [
        "print(np.mean(encoded_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-wC9thVs_fIC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, encoded_y, test_size=0.3, random_state=42, shuffle =True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4ZxQE5fk4fJ"
      },
      "source": [
        "## Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka3VibU2k3tI",
        "outputId": "236b51f3-6e07-4795-c9d0-638bd43cf91a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9037157184758662\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "logistic = LogisticRegression(random_state=42, class_weight={0: 0.705, 1: 0.295}) # если не указывать веса скор немного лучше\n",
        "#но после оптимизации скор выше при указании весов\n",
        "\n",
        "logistic.fit(X_train, y_train)\n",
        "\n",
        "preds = logistic.predict(X_val)\n",
        "\n",
        "print(roc_auc_score(preds, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNuDwTRTy8pq",
        "outputId": "b3d9dc18-9224-45ef-c0d1-7a111acb1f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 100}\n",
            "Best score: 0.9081090045731901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "logreg_params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "grid_search = GridSearchCV(logistic, logreg_params, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best score: {grid_search.best_score_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUr4cG_eyFph",
        "outputId": "253b0950-35c2-495a-f51a-504ca357dd51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9251340420256617\n"
          ]
        }
      ],
      "source": [
        "logistic = LogisticRegression(random_state=42, C= 10,class_weight={0: 0.705, 1: 0.295}, n_jobs=-1)\n",
        "\n",
        "logistic.fit(X_train, y_train)\n",
        "\n",
        "preds = logistic.predict(X_val)\n",
        "\n",
        "print(roc_auc_score(preds, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63LJFB7OvW7I"
      },
      "source": [
        "## Дерево"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f7xJKQh5r1-"
      },
      "source": [
        "В деревьях в данной задаче мало смысла (как, скорее всего и в лесе, и, вероятнее всего, в бустинге над деревьями)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "022IyFbBk3ph",
        "outputId": "0af22cdd-c115-4e31-973d-08b8a4366c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8509339548274325\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=42, class_weight={0: 0.705, 1: 0.295})\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "preds = tree.predict(X_val)\n",
        "\n",
        "print(roc_auc_score(preds, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2Vje--h061J",
        "outputId": "30579b84-bcb8-4744-eee0-d7b6a35da82f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': 50, 'max_features': None}\n",
            "Best score: 0.8738809244693602\n"
          ]
        }
      ],
      "source": [
        "tree_params = {'max_depth': [25, 50, 100, 150, 200],\n",
        "               'max_features': [None, 'sqrt', 'log2']}\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=42, class_weight={0: 0.705, 1: 0.295})\n",
        "grid_search = GridSearchCV(tree, tree_params, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best score: {grid_search.best_score_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjjqym7T06un",
        "outputId": "fc7afbfa-a710-4c7e-9e23-b557244c6e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8770942763668573\n"
          ]
        }
      ],
      "source": [
        "tree = DecisionTreeClassifier(random_state=42,\n",
        "                              class_weight={0: 0.705, 1: 0.295},\n",
        "                              max_depth=50,\n",
        "                              max_features=None)\n",
        "\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "preds = tree.predict(X_val)\n",
        "\n",
        "print(roc_auc_score(preds, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj9CyB6BvcCv"
      },
      "source": [
        "## Лес"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbOGhmTGk3mK",
        "outputId": "d6ba2d4c-ee29-4f09-ae1b-5c1a4273d89c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9196082403509229\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest = RandomForestClassifier(random_state=42,\n",
        "                                class_weight={0: 0.705, 1: 0.295},\n",
        "                                n_jobs=-1, n_estimators=300)\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "preds = forest.predict(X_val)\n",
        "\n",
        "print(roc_auc_score(preds, y_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "f4RJL4Gxsaxm",
        "outputId": "ef03cacb-8005-4f12-8858-cb7f89ed6dcd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-2cf27b0ffd52>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.705\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.295\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best parameters: {grid_search.best_params_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best score: {grid_search.best_score_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "forest_params = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 20, 30]}\n",
        "\n",
        "\n",
        "# ,\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2]\n",
        "forest = RandomForestClassifier(random_state=42, class_weight={0: 0.705, 1: 0.295}, n_jobs=-1)\n",
        "grid_search = GridSearchCV(forest, forest_params, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best score: {grid_search.best_score_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAuExeNjsauo"
      },
      "outputs": [],
      "source": [
        "forest = RandomForestClassifier(random_state=42,\n",
        "                              class_weight={0: 0.705, 1: 0.295},\n",
        "                              max_depth=50,\n",
        "                              n_jobs=-1)\n",
        "\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "preds = forest.predict(X_val)\n",
        "\n",
        "print(roc_auc_score(preds, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKCU32wAvg33"
      },
      "source": [
        "## Бустинг"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTZpSZa7k_Wd",
        "outputId": "40e77302-2d48-4e2a-afce-c503c714faf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9276389828763092\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "catboost = CatBoostClassifier(random_state=42, verbose=0)\n",
        "\n",
        "catboost.fit(X_train, y_train)\n",
        "\n",
        "preds = catboost.predict(X_val)\n",
        "\n",
        "print(roc_auc_score(preds, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOs9i6CvsdZA"
      },
      "outputs": [],
      "source": [
        "catboost = CatBoostClassifier(random_state=42, verbose=0, early_stopping_rounds=10)\n",
        "\n",
        "params = {\n",
        "    'iterations': [100, 300, 500],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'depth': [4, 10, 30],\n",
        "    'l2_leaf_reg': [1, 3, 5]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(catboost, params, cv=5, scoring='roc_auc')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8BUqvQI7h-z"
      },
      "outputs": [],
      "source": [
        "catboost = CatBoostClassifier(random_state=42, verbose=0)\n",
        "\n",
        "\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "preds = forest.predict(X_val)\n",
        "\n",
        "print(roc_auc_score(preds, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tegEmrHWk_t5"
      },
      "source": [
        "## Нейронка (обычная полносвязная)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZFLOt-Waw1E",
        "outputId": "8fa702cf-a672-44ca-9a77-0f82cf5babdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 0.10642208158969879, Training ROC AUC: 0.8806090787691429, Validation ROC AUC: 0.9576821375635614\n",
            "New best ROC AUC: 0.9576821375635614. Saving model...\n",
            "Epoch 2, Training Loss: 0.020895473659038544, Training ROC AUC: 0.9724971836123004, Validation ROC AUC: 0.9662120153559896\n",
            "New best ROC AUC: 0.9662120153559896. Saving model...\n",
            "Epoch 3, Training Loss: 0.06769150495529175, Training ROC AUC: 0.9846758727492798, Validation ROC AUC: 0.968591927774067\n",
            "New best ROC AUC: 0.968591927774067. Saving model...\n",
            "Epoch 4, Training Loss: 0.0005925592267885804, Training ROC AUC: 0.9916253093982049, Validation ROC AUC: 0.9677565136625548\n",
            "Epoch 5, Training Loss: 0.005129648372530937, Training ROC AUC: 0.9958439530023575, Validation ROC AUC: 0.969117910308828\n",
            "New best ROC AUC: 0.969117910308828. Saving model...\n",
            "Epoch 6, Training Loss: 1.653617982810829e-05, Training ROC AUC: 0.9975269468739568, Validation ROC AUC: 0.9676093162943088\n",
            "Epoch 7, Training Loss: 0.0030664820224046707, Training ROC AUC: 0.9983811285846438, Validation ROC AUC: 0.9685710603222795\n",
            "Epoch 8, Training Loss: 0.0003016417322214693, Training ROC AUC: 0.9985631275286823, Validation ROC AUC: 0.9654072886735767\n",
            "Epoch 9, Training Loss: 1.3525736903829966e-05, Training ROC AUC: 0.9985961814783169, Validation ROC AUC: 0.966268480225532\n",
            "Epoch 10, Training Loss: 0.00044888051343150437, Training ROC AUC: 0.9988257575200493, Validation ROC AUC: 0.9688638183958862\n",
            "Epoch 11, Training Loss: 2.249891076644417e-05, Training ROC AUC: 0.9989872769869504, Validation ROC AUC: 0.968371489741704\n",
            "Epoch 12, Training Loss: 9.187847172142938e-05, Training ROC AUC: 0.9989564290851226, Validation ROC AUC: 0.9685671732479267\n",
            "Epoch 13, Training Loss: 1.7881448002299294e-06, Training ROC AUC: 0.9989594440171249, Validation ROC AUC: 0.9692154963333636\n",
            "New best ROC AUC: 0.9692154963333636. Saving model...\n",
            "Epoch 14, Training Loss: 1.4136704521661159e-05, Training ROC AUC: 0.9990013221579853, Validation ROC AUC: 0.9683360969068094\n",
            "Epoch 15, Training Loss: 5.887769020773703e-06, Training ROC AUC: 0.9990532745838291, Validation ROC AUC: 0.9680430319589116\n",
            "Epoch 16, Training Loss: 5.893724310673809e-12, Training ROC AUC: 0.9990337878282047, Validation ROC AUC: 0.9667169258561026\n",
            "Epoch 17, Training Loss: 0.0002859159139916301, Training ROC AUC: 0.9990507743963151, Validation ROC AUC: 0.9686238427003302\n",
            "Epoch 18, Training Loss: 1.0231116152306825e-15, Training ROC AUC: 0.9990895640702464, Validation ROC AUC: 0.9674590501831528\n",
            "Epoch 19, Training Loss: 0.17675559222698212, Training ROC AUC: 0.9990147055146783, Validation ROC AUC: 0.9668346632924134\n",
            "Epoch 20, Training Loss: 0.007247325498610735, Training ROC AUC: 0.9988017851338851, Validation ROC AUC: 0.9681018495313518\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class SpamClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SpamClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(1000, 512)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.fc3 = nn.Linear(128, 32)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout3 = nn.Dropout(0.3)\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x.squeeze()\n",
        "\n",
        "model = SpamClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_data = TensorDataset(torch.tensor(X_train).float(), torch.tensor(y_train).float())\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "val_data = TensorDataset(torch.tensor(X_val).float(), torch.tensor(y_val).float())\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
        "\n",
        "def validate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    all_outputs = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            outputs = model(inputs)\n",
        "            all_outputs.extend(outputs.cpu().numpy())\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "    model.train()\n",
        "    roc_score = roc_auc_score(all_targets, all_outputs)\n",
        "    return roc_score\n",
        "\n",
        "def train_model(num_epochs):\n",
        "    best_roc_auc = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        all_train_outputs = []\n",
        "        all_train_targets = []\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            all_train_outputs.extend(outputs.detach().cpu().numpy())\n",
        "            all_train_targets.extend(targets.detach().cpu().numpy())\n",
        "\n",
        "        train_roc_auc = roc_auc_score(all_train_targets, all_train_outputs)\n",
        "        val_roc_auc = validate_model(model, val_loader)\n",
        "        print(f'Epoch {epoch+1}, Training Loss: {loss.item()}, Training ROC AUC: {train_roc_auc}, Validation ROC AUC: {val_roc_auc}')\n",
        "\n",
        "        if val_roc_auc > best_roc_auc:\n",
        "            best_roc_auc = val_roc_auc\n",
        "            print(f'New best ROC AUC: {best_roc_auc}. Saving model...')\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "train_model(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBSbb85jH8DH"
      },
      "source": [
        "## Обучим на всей выборке"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я решил, что в данном случае имеет место обучение на всех данных по двум причинам:\n",
        "1. состоятельность прогнозов при небольшом количестве эпох\n",
        "2. несмещенность при сравнении логситической и nn, обученных только на тестовых данных (сравненение предиктов дает почти всех метрик точности давало ~90%)\n",
        "\n",
        "но это касается только линейных моделей, деревья и все, что с ними связано трудно сказать нечто подобное (метрики типа accuracy, roc_auc дают 58-65%)\n",
        "поэтому выбор в пользу нейросети"
      ],
      "metadata": {
        "id": "WYJRz0ltq5ta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2Z-QH3IxTLWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14cf94fa-6e87-4505-e24e-3fd1165b778b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 0.15256589651107788, Training ROC AUC: 0.9199367445086588\n",
            "Epoch 2, Training Loss: 0.15868474543094635, Training ROC AUC: 0.9753473252851298\n",
            "Epoch 3, Training Loss: 0.15745721757411957, Training ROC AUC: 0.9857674872518379\n",
            "Epoch 4, Training Loss: 0.1520531177520752, Training ROC AUC: 0.9921021471696713\n",
            "Epoch 5, Training Loss: 0.1011425331234932, Training ROC AUC: 0.9962422413971131\n",
            "Epoch 6, Training Loss: 0.06797458231449127, Training ROC AUC: 0.997617579921653\n",
            "Epoch 7, Training Loss: 0.020524239167571068, Training ROC AUC: 0.9982887319223241\n",
            "Epoch 8, Training Loss: 0.005465001333504915, Training ROC AUC: 0.9985932043416792\n",
            "Epoch 9, Training Loss: 0.002809339901432395, Training ROC AUC: 0.998776779834204\n",
            "Epoch 10, Training Loss: 8.697345037944615e-05, Training ROC AUC: 0.998826286291719\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class SpamClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SpamClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(1000, 512)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.3)  # Dropout после первого слоя ReLU\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.3)  # Dropout после второго слоя ReLU\n",
        "        self.fc3 = nn.Linear(128, 32)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout3 = nn.Dropout(0.3)  # Dropout после третьего слоя ReLU\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x.squeeze()\n",
        "\n",
        "model = SpamClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_data = TensorDataset(torch.tensor(X).float(), torch.tensor(encoded_y).float())\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "def train_model(num_epochs):\n",
        "    best_roc_auc = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        all_train_outputs = []\n",
        "        all_train_targets = []\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            all_train_outputs.extend(outputs.detach().cpu().numpy())\n",
        "            all_train_targets.extend(targets.detach().cpu().numpy())\n",
        "\n",
        "        train_roc_auc = roc_auc_score(all_train_targets, all_train_outputs)\n",
        "        print(f'Epoch {epoch+1}, Training Loss: {loss.item()}, Training ROC AUC: {train_roc_auc}')\n",
        "\n",
        "\n",
        "train_model(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PzDl-bE1hmtE"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('test_spam.csv')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "test_data['text'] = test_data['text'].apply(preprocess_text)\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000, min_df=5, max_df=0.7)\n",
        "X_test = vectorizer.fit_transform(test_data['text']).toarray()\n",
        "\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test).float().to(device)\n",
        "\n",
        "model = SpamClassifier()\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test_tensor)\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "output = pd.DataFrame(data={\"prediction\": predictions.flatten()})\n",
        "output.to_csv(\"predictions.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}